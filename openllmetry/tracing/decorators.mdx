---
title: "Decorators"
description: "Enrich your traces by annotating chains and workflows in your app"
---

Traceloop SDK supports several decorators that can be used instead of manually starting a span.
You also get extra visibility into your LLM application structure.

## Workflows and Tasks

Sometimes called a "chain", is a decorator for a multi-step process that can be traced as a single unit.

<Tabs>
<Tab title="Python">

Use it as `@workflow(name="my_workflow")`.
We will consider every call to OpenAI as a distinct step (or task). You can even annotate the task with a name, using `@task(name="my_task")`.

<Tip>
  The `name` argument is optional. If you don't provide it, we will use the
  function name as the workflow or task name.
</Tip>

```python
from traceloop.sdk.decorators import workflow, task

@task(name="joke_creation")
def create_joke():
    completion = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": "Tell me a joke about opentelemetry"}],
    )

    return completion.choices[0].message.content

@task(name="signature_generation")
def generate_signature(joke: str):
    completion = openai.Completion.create(
        model="text-davinci-003",[]
        prompt="add a signature to the joke:\n\n" + joke,
    )

    return completion.choices[0].text


@workflow(name="pirate_joke_generator")
def joke_workflow():
    eng_joke = create_joke()
    pirate_joke = translate_joke_to_pirate(eng_joke)
    signature = generate_signature(pirate_joke)
    print(pirate_joke + "\n\n" + signature)
```

</Tab>
<Tab title="Typescript">
<Note>
This feature is only available in Typescript. You'll need to update your `tsconfig.json` to enable decorators.
</Note>

Update `tsconfig.json` to enable decorators:

```json
{
  "compilerOptions": {
    "experimentalDecorators": true
  }
}
```

Use it in your code `@traceloop.workflow("my_workflow")` for class methods only.
We will consider every call to OpenAI as a distinct step (or task). You can even annotate the task with a name, using `@traceloop.task("my_task")`.

<Tip>
  The name is optional. If you don't provide it, we will use the function name
  as the workflow or task name.
</Tip>

```js
import * as traceloop from "@traceloop/node-server-sdk";

class JokeCreation {
  @traceloop.task("joke_creation")
  async create_joke() {
    completion = await openai.chat.completions({
      model: "gpt-3.5-turbo",
      messages: [
        { role: "user", content: "Tell me a joke about opentelemetry" },
      ],
    });

    return completion.choices[0].message.content;
  }

  @traceloop.task("signature_generation")
  async generate_signature(joke: string) {
    completion = await openai.completions.create({
      model: "text-davinci-003",
      prompt: "add a signature to the joke:\n\n" + joke,
    });

    return completion.choices[0].text;
  }

  @traceloop.workflow("pirate_joke_generator")
  async joke_workflow() {
    eng_joke = create_joke();
    pirate_joke = await translate_joke_to_pirate(eng_joke);
    signature = await generate_signature(pirate_joke);
    console.log(pirate_joke + "\n\n" + signature);
  }
}
```

</Tab>
</Tabs>

## Agents and Tools

Similarily, if you use autonomous agents, you can use the `@agent` decorator to trace them as a single unit.
Each tool should be marked with `@tool`.

<Tabs>
<Tab title="Python">

```python
from traceloop.sdk.decorators import agent, tool

@agent(name="joke_translation")
def translate_joke_to_pirate(joke: str):
    completion = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": f"Translate the below joke to pirate-like english:\n\n{joke}"}],
    )

    history_jokes_tool()

    return completion.choices[0].message.content


@tool(name="history_jokes")
def history_jokes_tool():
    completion = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": f"get some history jokes"}],
    )

    return completion.choices[0].message.content
```

</Tab>
<Tab title="Typescript">
<Note>
Remember to set `experimentalDecorators` to `true` in your `tsconfig.json`.
</Note>
```js
import * as traceloop from "@traceloop/node-server-sdk";

class Agent {
@traceloop.agent("joke_translation")
async translate_joke_to_pirate(joke: str) {
completion = await openai.chat.completions.create({
model="gpt-3.5-turbo",
messages=[{"role": "user", "content": f"Translate the below joke to pirate-like english:\n\n{joke}"}],
})

        history_jokes_tool()

        return completion.choices[0].message.content

    }

    @traceloop.tool("history_jokes")
    async history_jokes_tool() {
        completion = await openai.chat.completions.create({
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": f"get some history jokes"}],
        })

            return completion.choices[0].message.content

    }

}

````
</Tab>
</Tabs>

## Decorating Classes (Python only)

While the examples above shows how to decorate functions, you can also decorate classes.
In this case, you will also need to provide the name of the method that runs the workflow, task, agent or tool.

```python Python
from traceloop.sdk.decorators import agent

@agent(name="base_joke_generator", method_name="generate_joke")
class JokeAgent:
    def generate_joke(self):
        completion = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": "Tell me a joke about Traceloop"}],
        )

        return completion.choices[0].message.content
```

## Async methods and classes (Python only)

All decorators have an equivalent async decorator.

So, if you're decorating an `async` method, use `@aworkflow`, `@atask` and so forth.

<Note>
  Javascript support async methods with the regular decorators,
  `traceloop.workflow()`, `traceloop.task()`, etc.
</Note>

See also a [separate section on using threads with OpenLLMetry](tracing/python-threads).